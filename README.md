ğŸ§  DOA-NET: Spatio-Temporal Deepfake Detection using Eye Blink Patterns

Dynamic Ocular Analysis Network (DOA-NET) is a spatio-temporal deepfake detection system that leverages periocular physiological cues, specifically eye blinking dynamics, to detect high-quality deepfake videos.

This project addresses the limitations of spatial-only deepfake detectors by integrating CNN-based spatial analysis with LSTM-based temporal modeling of Eye Aspect Ratio (EAR) signals.

ğŸ“Œ Key Highlights

âœ… Hybrid CNN + LSTM architecture

ğŸ‘ï¸ Physiological signal-based detection (Eye Blinking)

â±ï¸ Spatio-temporal feature fusion

ğŸ” Grad-CAM explainability for forensic analysis

ğŸŒ Cross-dataset generalization

âš¡ Real-time inference support

Video Input
   â†“
Frame Extraction
   â†“
Face & Eye Landmark Detection (MediaPipe)
   â†“
Eye Region Cropping
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spatial Path  â”‚ Temporal Path   â”‚
â”‚ (CNN)         â”‚ (EAR â†’ LSTM)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“ Feature Fusion
        â†“
   Binary Classification
        â†“
   Real / Fake Output
        â†“
   Grad-CAM Visualization


ğŸ› ï¸ Tech Stack

Language: Python 3.8+

Deep Learning: TensorFlow / Keras

Computer Vision: OpenCV, MediaPipe

ML Utilities: NumPy, Pandas, Scikit-learn

Visualization: Matplotlib, Seaborn

Backend API: FastAPI

Frontend: React (Vite)

Deployment: Uvicorn

ğŸ“‚ Project Structure
deepfake_detection/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ real_videos/
â”‚   â””â”€â”€ fake_videos/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ classifier.pkl
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ prediction_reports/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ feature_extraction/
â”‚   â”œâ”€â”€ model/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/roshanavatirak/NeuroBlink---Deepfake-Video-Detection-by-using-Eye-Blink-Pattern.git
cd NeuroBlink

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Initialize MediaPipe
python -c "import mediapipe as mp; mp.solutions.face_mesh.FaceMesh()"

ğŸ§  Training the Model
Basic Training
python train.py --real-dir data/real_videos --fake-dir data/fake_videos

Advanced Options

Train with SVM classifier

python train.py --real-dir data/real_videos --fake-dir data/fake_videos --model-type svm


Custom model save path

python train.py --real-dir data/real_videos --fake-dir data/fake_videos --model-path models/my_classifier.pkl


Skip visualizations (faster training)

python train.py --real-dir data/real_videos --fake-dir data/fake_videos --no-visualizations

ğŸ” Making Predictions
Single Video
python predict.py --video test_video.mp4

With HTML Report
python predict.py --video test_video.mp4 --save-report

Real-Time Visualization
python predict.py --video test_video.mp4 --visualize

All Options Combined
python predict.py --video test_video.mp4 --save-report --visualize --model models/classifier.pkl

Batch Prediction
python predict.py --batch-dir test_videos/ --output batch_results.json

ğŸš€ Running the Backend (FastAPI)
venv\Scripts\activate
uvicorn main:app --reload


Backend available at:

http://127.0.0.1:8000

ğŸ¨ Running the Frontend
npm install
npm run dev

ğŸ“Š Performance Summary
Dataset	Accuracy	AUC
FaceForensics++	99.1%	0.998
Celeb-DF (v2)	97.6%	0.991
DFDC	91.2%	0.953
ğŸ§ª Core Insight

Deepfake models struggle to replicate the natural variability and spontaneity of human eye blinking.
DOA-NET exploits this physiological limitation using spatio-temporal modeling.

ğŸ”® Future Scope

Multimodal fusion (audio + head pose)

Compression-robust detection

Diffusion-based deepfake adaptation

LLM-assisted forensic explanation

Real-time deployment optimization

ğŸ‘¨â€ğŸ”¬ Authors

Dr. Nikita Mohod

Dr. Amar Sable

Shravani Balapure

Roshan Avatirak

Anand Tayde

Nishchay Sahu

Pratik Girnare

Department of Computer Science & Engineering
Sipna College of Engineering and Technology, Amravati, India
